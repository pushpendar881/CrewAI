{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hYZeNpFN7S-V"
      },
      "outputs": [],
      "source": [
        "!pip install crewai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bvlIwf1f7ar0"
      },
      "outputs": [],
      "source": [
        "!pip install crewai crewai-tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZ-x5zsk75kg"
      },
      "outputs": [],
      "source": [
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1KYLfgb3Kwq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N9WYw8xPmKs"
      },
      "source": [
        "# **IMPORTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uGPQHTM8B6G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from crewai import Agent, Task, Crew\n",
        "from crewai_tools import (\n",
        "  FileReadTool,\n",
        "  ScrapeWebsiteTool,\n",
        "  PDFSearchTool,\n",
        "  SerperDevTool\n",
        ")\n",
        "from crewai import LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrpkE9EC8DkS"
      },
      "outputs": [],
      "source": [
        "\n",
        "os.environ[\"SERPER_API_KEY\"] = \"API_KEy\"\n",
        "os.environ['MISTRAL_API_KEY'] = \"API_KEY\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkXx6--o7n7p"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM8bVmIsP2g0"
      },
      "source": [
        "# **TOOLS for the CREW**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8t_JA7BOt8j"
      },
      "source": [
        "# **Semantic Search on Resume Using Mistral AI and Google Embeddings**\n",
        "\n",
        "This parts is use to perform a semantic search on a resume PDF using the Mistral AI model for language understanding and Google embeddings for document retrieval. The configuration ensures that we can effectively match job descriptions with relevant parts of the resume."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg1vS1d_8PVw"
      },
      "outputs": [],
      "source": [
        "# Initialize the semantic search tool for resume search using Mistral AI and Google embeddings\n",
        "semantic_search_resume = PDFSearchTool(\n",
        "    config=dict(\n",
        "        # Configure the language model to use Mistral AI as the provider\n",
        "        llm=dict(\n",
        "            provider=\"mistralai\",  # Change to use Mistral AI as the provider\n",
        "            config=dict(\n",
        "                model=\"mistral-7B\",  # Specify the Mistral AI model to use\n",
        "            ),\n",
        "        ),\n",
        "        # Configure the embedding model to use Google's document retrieval embedding model\n",
        "        embedder=dict(\n",
        "            provider=\"google\",  # You can change this to other providers like openai, ollama, etc.\n",
        "            config=dict(\n",
        "                model=\"models/embedding-001\",  # Specify the embedding model for retrieval tasks\n",
        "                task_type=\"retrieval_document\",  # Define the task type as document retrieval\n",
        "            ),\n",
        "        ),\n",
        "    ),\n",
        "    # Specify the path to the resume PDF for semantic search\n",
        "    mdx=\"Your_pdf.pdf\"  # Path to the resume PDF file\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0vUpuJfQPl8"
      },
      "source": [
        "# Semantic Search with SerperDev, Web Scraping, and Resume File Reading\n",
        "\n",
        "This part demonstrates the use of multiple tools for performing semantic search, web scraping, and reading a resume PDF. The SerperDev tool is used for search queries, the ScrapeWebsite tool extracts information from web pages, and the FileRead tool is used to read the resume for analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oS7nyUg58VYX"
      },
      "outputs": [],
      "source": [
        "# Initialize the search tool using SerperDev for semantic search capabilities\n",
        "search_tool = SerperDevTool(\n",
        "      config=dict(\n",
        "        engine=\"google_scholar\",  # Use Google Scholar for research-oriented searches\n",
        "        num_results=10,          # Get more results\n",
        "    )\n",
        ")\n",
        "\n",
        "# Initialize the web scraping tool to extract content from websites\n",
        "scrape_tool = ScrapeWebsiteTool()\n",
        "\n",
        "# Initialize the file reading tool to read the resume PDF file for further analysis\n",
        "read_resume = FileReadTool(file_path=\"path.pdf\")  # Path to the resume PDF file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViaEqVvXQ26b"
      },
      "source": [
        "# **Configuring LLMs with Mistral and Gemini Models for Language Tasks**\n",
        "\n",
        "This section demonstrates how to configure two separate LLM instances using the Mistral and Gemini models. These LLMs will be used for different natural language processing tasks, such as semantic search or content generation. The parameters like model temperature and API keys are customizable based on the user's needs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JdVUHe28YCc"
      },
      "outputs": [],
      "source": [
        "mistral = LLM(\n",
        "    model=\"mistral-small-2402\",  # Specify the Mistral model to use\n",
        "    temperature=0.1,  # Adjust the creativity level of the model's responses\n",
        "    base_url=\"https://api.mistral.ai/v1\",  # Base URL for the Mistral API\n",
        "    api_key=\"API_KEY\"  # Your Mistral API key (replace as needed)\n",
        ")\n",
        "\n",
        "\n",
        "gemini = LLM(\n",
        "    model=\"gemini/gemini-pro\",  # Specify the Gemini model\n",
        "    temperature=0.1,  # Control the level of variability in the model's output\n",
        "    api_key=\"API_KEY\"  # Your Gemini API key (replace as needed)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN_J1B_jRL5U"
      },
      "source": [
        "# **AGENTS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIR4Xa-xRXUj"
      },
      "source": [
        "# Agent 1: Tech Job Researcher for Job Posting Analysis\n",
        "\n",
        "This section introduces the `Tech Job Researcher` agent, whose goal is to analyze job postings and provide valuable insights to help job applicants. The agent uses various tools, such as web scraping and search, combined with an LLM (Mistral model) to perform in-depth research and data extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "058jnyAk9hMm"
      },
      "outputs": [],
      "source": [
        "researcher = Agent(\n",
        "    role=\"Tech Job Researcher\",  # Define the role of the agent\n",
        "    goal=\"Make sure to do amazing analysis on \"\n",
        "         \"job posting to help job applicants\",  # Set the goal for the agent\n",
        "    tools=[scrape_tool, search_tool],  # Assign the necessary tools for research (scraping and search)\n",
        "    verbose=True,  # Enable verbose mode to print detailed process logs\n",
        "    backstory=(\n",
        "        \"As a Job Researcher, your prowess in \"\n",
        "        \"navigating and extracting critical \"\n",
        "        \"information from job postings is unmatched.\"\n",
        "        \"Your skills help pinpoint the necessary \"\n",
        "        \"qualifications and skills sought \"\n",
        "        \"by employers, forming the foundation for \"\n",
        "        \"effective application tailoring.\"  # Backstory for the agent's expertise\n",
        "    ),\n",
        "    llm=gemini\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOOKgCPmRjKs"
      },
      "source": [
        "# Agent 2: Personal Profiler for Engineers\n",
        "\n",
        "This section introduces the `Personal Profiler for Engineers`, whose goal is to perform thorough research on job applicants to help them stand out in the competitive job market. The agent utilizes various tools, including scraping, resume analysis, and semantic search, and is powered by an LLM (Mistral model) to provide personalized profile-building insights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SpD6o_p9j1p"
      },
      "outputs": [],
      "source": [
        "# Initialize the second agent, 'Personal Profiler for Engineers', for applicant profiling\n",
        "profiler = Agent(\n",
        "    role=\"Personal Profiler for Engineers\",  # Define the agent's role as a profiler for engineers\n",
        "    goal=\"Do incredible research on job applicants \"\n",
        "         \"to help them stand out in the job market\",  # Set the goal to improve applicants' visibility in the job market\n",
        "    tools=[scrape_tool, search_tool, read_resume, semantic_search_resume],  # Assign tools for scraping, searching, and resume analysis\n",
        "    verbose=True,  # Enable verbose mode for detailed output logs\n",
        "    backstory=(\n",
        "        \"Equipped with analytical prowess, you dissect \"\n",
        "        \"and synthesize information \"\n",
        "        \"from diverse sources to craft comprehensive \"\n",
        "        \"personal and professional profiles, laying the \"\n",
        "        \"groundwork for personalized resume enhancements.\"  # Backstory describing the agent's expertise in profiling\n",
        "    ),\n",
        "    llm=mistral\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "schoeAumR0cT"
      },
      "source": [
        "# Agent 3: Resume Strategist for Engineers\n",
        "\n",
        "This section introduces the `Resume Strategist for Engineers`, an agent whose purpose is to identify the most effective ways to make resumes stand out in the competitive job market. Using tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1XTUomF9mOb"
      },
      "outputs": [],
      "source": [
        "# Initialize the third agent, 'Resume Strategist for Engineers', for resume optimization\n",
        "resume_strategist = Agent(\n",
        "    role=\"Resume Strategist for Software Engineers\",  # Define the agent's role focused on resume strategy\n",
        "    goal=\"Find all the best ways to make a \"\n",
        "         \"resume stand out in the job market.\",  # Set the goal to optimize resumes for better visibility\n",
        "    tools=[read_resume, semantic_search_resume],  # Assign tools for resume analysis, web scraping, and job searching\n",
        "    verbose=True,  # Enable verbose mode for detailed logging of the agent's actions\n",
        "    backstory=(\n",
        "        \"With a strategic mind and an eye for detail, you \"\n",
        "        \"excel at refining resumes to highlight the most \"\n",
        "        \"relevant skills and experiences, ensuring they \"\n",
        "        \"resonate perfectly with the job's requirements.\"  # Backstory highlighting the agent's expertise in resume optimization\n",
        "    ),\n",
        "    llm=mistral\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kD2NimfSBrz"
      },
      "source": [
        "# Agent 4: Engineering Interview Preparer\n",
        "\n",
        "This section introduces the `Engineering Interview Preparer`, an agent designed to generate interview questions and talking points based on a candidate's resume and job requirements. Using tools for scraping, searching, and resume analysis, this agent, powered by the Gemini model, ensures that candidates are well-prepared for job interviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ti_D_tOw9paT"
      },
      "outputs": [],
      "source": [
        "# Initialize the fourth agent, 'Engineering Interview Preparer', for interview preparation\n",
        "interview_preparer = Agent(\n",
        "    role=\"Engineering Interview Preparer\",  # Define the agent's role as an interview preparer\n",
        "    goal=\"Create interview questions and talking points \"\n",
        "         \"based on the resume and job requirements\",  # Set the goal to help candidates prepare for interviews\n",
        "    tools=[scrape_tool, search_tool, read_resume, semantic_search_resume],  # Assign tools for scraping, searching, and resume analysis\n",
        "    verbose=True,  # Enable verbose mode to print detailed logs of the agent's actions\n",
        "    backstory=(\n",
        "        \"Your role is crucial in anticipating the dynamics of \"\n",
        "        \"interviews. With your ability to formulate key questions \"\n",
        "        \"and talking points, you prepare candidates for success, \"\n",
        "        \"ensuring they can confidently address all aspects of the \"\n",
        "        \"job they are applying for.\"  # Backstory highlighting the agent's expertise in interview preparation\n",
        "    ),\n",
        "    llm=gemini\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Cnux7F6SUIa"
      },
      "source": [
        "# **TASK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIKT12U6S5Rr"
      },
      "source": [
        "# Task for Researcher Agent: Extract Job Requirements\n",
        "\n",
        "This section demonstrates how to assign a task to the `Researcher Agent` to analyze a job posting URL and extract key job requirements, including necessary skills, qualifications, and experiences. The task uses the agent’s tools and expertise to gather and categorize this information in a structured format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOLCRFQO9rn6"
      },
      "outputs": [],
      "source": [
        "# Task for Researcher Agent: Extract Job Requirements\n",
        "research_task = Task(\n",
        "    description=(\n",
        "        \"Analyze the job posting URL provided ({job_posting_url}) \"\n",
        "        \"to extract key skills, experiences, and qualifications \"\n",
        "        \"required. Use the tools to gather content and identify \"\n",
        "        \"and categorize the requirements.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A structured list of job requirements, including necessary \"\n",
        "        \"skills, qualifications, and experiences.\"\n",
        "    ),\n",
        "    agent=researcher,\n",
        "    async_execution=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfO4o3YsS_pk"
      },
      "source": [
        "# Task for Profiler Agent: Compile Comprehensive Profile\n",
        "\n",
        "This section outlines a task for the `Profiler Agent` to compile a detailed personal and professional profile using information from a GitHub URL and a personal write-up. The task involves synthesizing information from these sources to create a comprehensive profile document.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvRUV42i9tUT"
      },
      "outputs": [],
      "source": [
        "profile_task = Task(\n",
        "    description=(\n",
        "        \"Compile a detailed personal and professional profile \"  # Task description indicating the need for a profile compilation\n",
        "        \"using the GitHub ({github_url}) URLs, and personal write-up \"\n",
        "        \"({personal_writeup}). Utilize tools to extract and \"\n",
        "        \"synthesize information from these sources.\"  # Guide the agent to extract and synthesize information\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A comprehensive profile document that includes skills, \"  # Specify the expected output as a detailed profile\n",
        "        \"project experiences, contributions, interests, and \"\n",
        "        \"communication style.\"  # Outline the key components to be included in the profile\n",
        "    ),\n",
        "    agent=profiler,  # Assign the Profiler Agent to complete the task\n",
        "    async_execution=True  # Enable asynchronous execution to allow the agent to work in the background\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZHjwYIXTKez"
      },
      "source": [
        "# Task for Resume Strategist Agent: Align Resume with Job Requirements\n",
        "\n",
        "This section describes a task for the `Resume Strategist Agent` to tailor a candidate's resume based on their profile and the job requirements extracted from previous tasks. The objective is to enhance the resume's content to better reflect the candidate’s abilities in alignment with the job posting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6s3zoc3T9um2"
      },
      "outputs": [],
      "source": [
        "# Task for Resume Strategist Agent: Align Resume with Job Requirements\n",
        "resume_strategy_task = Task(\n",
        "    description=(\n",
        "        \"Using **only** the profile and job requirements obtained from \"\n",
        "        \"previous tasks, tailor the resume to highlight the most \"\n",
        "        \"relevant areas. Employ tools to adjust and enhance the \"\n",
        "        \"resume content. Make sure this is the best resume even but \"\n",
        "        \"don't make up any information. Update every section, \"\n",
        "        \"inlcuding the initial summary, work experience, skills, \"\n",
        "        \"and education. All to better reflrect the candidates \"\n",
        "        \"abilities and how it matches the job posting.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"An updated resume that effectively highlights the candidate's \"\n",
        "        \"qualifications and experiences relevant to the job.\"\n",
        "    ),\n",
        "    output_file=\"tailored_resume.md\",\n",
        "    context=[research_task, profile_task],\n",
        "    agent=resume_strategist\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKuKy9OQTa1a"
      },
      "source": [
        "# Task for Interview Preparer Agent: Develop Interview Materials\n",
        "\n",
        "This section outlines a task for the `Interview Preparer Agent` to create a list of potential interview questions and talking points based on the tailored resume and job requirements. The goal is to help the candidate prepare effectively for their interview by focusing on relevant discussion points that align with their qualifications and the job posting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88r7mW7E9v69"
      },
      "outputs": [],
      "source": [
        "# Task for Interview Preparer Agent: Develop Interview Materials\n",
        "interview_preparation_task = Task(\n",
        "    description=(\n",
        "        \"Create a list of 10 potential interview questions and talking \"\n",
        "        \"points based on the tailored resume and job requirements. \"\n",
        "        \"Utilize tools to generate relevant questions and discussion \"\n",
        "        \"points. Make sure to use these question and talking points to \"\n",
        "        \"help the candiadte highlight the main points of the resume \"\n",
        "        \"and how it matches the job posting.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A document containing key questions and talking points \"\n",
        "        \"that the candidate should prepare for the initial interview.\"\n",
        "    ),\n",
        "    output_file=\"interview_materials.md\",\n",
        "    context=[research_task, profile_task, resume_strategy_task],\n",
        "    agent=interview_preparer\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ya25SUSoSZ4i"
      },
      "source": [
        "# Job Application Crew Setup\n",
        "\n",
        "This section defines the `Job Application Crew`, which comprises multiple agents working collaboratively to assist candidates in their job application process. The crew includes a researcher, profiler, resume strategist, and interview preparer, each tasked with specific responsibilities to streamline the application journey."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzfiZ_WO9xQd"
      },
      "outputs": [],
      "source": [
        "job_application_crew = Crew(\n",
        "    agents=[researcher,\n",
        "            profiler,\n",
        "            resume_strategist,\n",
        "            interview_preparer],\n",
        "\n",
        "    tasks=[research_task,\n",
        "           profile_task,\n",
        "           resume_strategy_task,\n",
        "           interview_preparation_task],\n",
        "\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDR3okEtSejV"
      },
      "source": [
        "# **Runnig the Crew**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJfSHNOa9yuk"
      },
      "outputs": [],
      "source": [
        "job_application_inputs = {\n",
        "    'job_posting_url': 'https://branchinternational.applytojob.com/apply/nT6J8qzm72/ML-Engineer-Intern?source=Our%20Career%20Page%20Widget',\n",
        "    'github_url': 'YOUR_GITHUB_LINK',\n",
        "    'personal_writeup': \"\"\"Hello, my name is (name). I am a third-year engineering student at VESIT (Mumbai), majoring in Artificial Intelligence and\n",
        "Data Science. Over the past two years, I've developed a strong proficiency in Full Stack Web Development, having\n",
        "completed several projects that showcase my skills in building comprehensive applications. I have a solid grasp of core\n",
        "Java and am well-versed in machine learning algorithms. Currently, I am actively solving LeetCode problems, with a\n",
        "rating of 1550, and am expanding my knowledge in Deep Learning and Generative AI.\n",
        "\"\"\"\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HA8ditH3Y_HV"
      },
      "outputs": [],
      "source": [
        "result = job_application_crew.kickoff(inputs=job_application_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SabuhXAll4Jq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}